{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-29T08:27:01.928826Z",
     "iopub.status.busy": "2020-08-29T08:27:01.927851Z",
     "iopub.status.idle": "2020-08-29T08:27:12.529547Z",
     "shell.execute_reply": "2020-08-29T08:27:12.528851Z"
    },
    "papermill": {
     "duration": 10.623182,
     "end_time": "2020-08-29T08:27:12.529697",
     "exception": false,
     "start_time": "2020-08-29T08:27:01.906515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using distribution strategy: MirroredStrategy\n",
      "Number of replicas in sync: 1\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    strategy = tf.distribute.MirroredStrategy()  # Multi-GPU strategy\n",
    "    strategy_name = \"MirroredStrategy\"\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()  # Default CPU strategy\n",
    "    strategy_name = \"DefaultStrategy\"\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "print(f\"Using distribution strategy: {strategy_name}\")\n",
    "print(f\"Number of replicas in sync: {strategy.num_replicas_in_sync}\")    \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T08:27:13.928234Z",
     "iopub.status.busy": "2020-08-29T08:27:13.927282Z",
     "iopub.status.idle": "2020-08-29T08:27:13.932144Z",
     "shell.execute_reply": "2020-08-29T08:27:13.931490Z"
    },
    "papermill": {
     "duration": 0.329473,
     "end_time": "2020-08-29T08:27:13.932267",
     "exception": false,
     "start_time": "2020-08-29T08:27:13.602794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_filepath = '/Users/kylewong/Downloads/NN_Project_Week_5'\n",
    "file_names_monet = tf.io.gfile.glob(str(project_filepath + '/monet_tfrec/*.tfrec'))\n",
    "file_names_photo = tf.io.gfile.glob(str(project_filepath + '/photo_tfrec/*.tfrec'))\n",
    "IMAGE_SIZE = [256, 256]\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "strategy = tf.distribute.get_strategy()\n",
    "\n",
    "def image_to_data(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(pic):\n",
    "    pic_format = {\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    # Parse the TFRecord example\n",
    "    example = tf.io.parse_single_example(pic, pic_format)\n",
    "    # Preprocess the image\n",
    "    image = image_to_data(example['image'])\n",
    "    return image\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load the datasets\n",
    "dataset_monet = load_dataset(file_names_monet, labeled=True).batch(1)\n",
    "dataset_photo = load_dataset(file_names_photo, labeled=True).batch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T08:27:16.323098Z",
     "iopub.status.busy": "2020-08-29T08:27:16.322049Z",
     "iopub.status.idle": "2020-08-29T08:27:16.325579Z",
     "shell.execute_reply": "2020-08-29T08:27:16.324929Z"
    },
    "papermill": {
     "duration": 0.026742,
     "end_time": "2020-08-29T08:27:16.325757",
     "exception": false,
     "start_time": "2020-08-29T08:27:16.299015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def downsample_residual(filters, size, use_residual=True):\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "    def block(x):\n",
    "        # Main convolutional path\n",
    "        conv = tf.keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=size,\n",
    "            strides=2,\n",
    "            padding='same',\n",
    "            kernel_initializer=initializer,\n",
    "            use_bias=False\n",
    "        )(x)\n",
    "        conv = tf.keras.layers.BatchNormalization()(conv)\n",
    "        conv = tf.keras.layers.ReLU()(conv)\n",
    "\n",
    "        if use_residual:\n",
    "            # Residual connection\n",
    "            shortcut = tf.keras.layers.Conv2D(\n",
    "                filters=filters,\n",
    "                kernel_size=1,\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "                kernel_initializer=initializer,\n",
    "                use_bias=False\n",
    "            )(x)\n",
    "            shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
    "            conv = tf.keras.layers.Add()([conv, shortcut])\n",
    "\n",
    "        return conv\n",
    "\n",
    "    return block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T08:27:16.388875Z",
     "iopub.status.busy": "2020-08-29T08:27:16.388093Z",
     "iopub.status.idle": "2020-08-29T08:27:16.391770Z",
     "shell.execute_reply": "2020-08-29T08:27:16.390974Z"
    },
    "papermill": {
     "duration": 0.026678,
     "end_time": "2020-08-29T08:27:16.391892",
     "exception": false,
     "start_time": "2020-08-29T08:27:16.365214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upsample_pixel_shuffle(filters, size, upscale_factor=2, apply_dropout=False):\n",
    "\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "    def block(x):\n",
    "        # Convolution with filters multiplied by upscale factor squared\n",
    "        conv = tf.keras.layers.Conv2D(\n",
    "            filters=filters * (upscale_factor ** 2),\n",
    "            kernel_size=size,\n",
    "            padding='same',\n",
    "            kernel_initializer=initializer,\n",
    "            use_bias=False\n",
    "        )(x)\n",
    "        # Pixel shuffle operation\n",
    "        x = tf.keras.layers.Lambda(lambda x: tf.nn.depth_to_space(x, block_size=upscale_factor))(conv)\n",
    "\n",
    "        # Optionally apply dropout\n",
    "        if apply_dropout:\n",
    "            x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "        # Apply ReLU activation\n",
    "        return tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    return block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T08:27:16.462513Z",
     "iopub.status.busy": "2020-08-29T08:27:16.461714Z",
     "iopub.status.idle": "2020-08-29T08:27:16.465151Z",
     "shell.execute_reply": "2020-08-29T08:27:16.464516Z"
    },
    "papermill": {
     "duration": 0.033907,
     "end_time": "2020-08-29T08:27:16.465273",
     "exception": false,
     "start_time": "2020-08-29T08:27:16.431366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_generator(input_shape=(256, 256, 3), output_channels=3):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Define the initializer for all layers\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "    # Downsampling Blocks with Residual Connections\n",
    "    def residual_downsample(x, filters, size, use_instance_norm=True):\n",
    "        conv = tf.keras.layers.Conv2D(filters, size, strides=2, padding=\"same\", kernel_initializer=initializer)(x)\n",
    "        if use_instance_norm:\n",
    "            conv = tfa.layers.InstanceNormalization()(conv)\n",
    "        conv = tf.keras.layers.ReLU()(conv)\n",
    "\n",
    "        # Residual Connection\n",
    "        shortcut = tf.keras.layers.Conv2D(filters, 1, strides=2, padding=\"same\", kernel_initializer=initializer)(x)\n",
    "        return tf.keras.layers.Add()([conv, shortcut])\n",
    "\n",
    "    # Upsampling Block with Attention Mechanism\n",
    "    def attention_upsample(x, skip, filters, size, use_dropout=False):\n",
    "        initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "        # Resize the skip connection to match the spatial dimensions of x\n",
    "        skip_resized = tf.keras.layers.Resizing(x.shape[1], x.shape[2])(skip)\n",
    "\n",
    "        # Attention Gate\n",
    "        g1 = tf.keras.layers.Conv2D(filters, 1, strides=1, padding=\"same\", kernel_initializer=initializer)(x)\n",
    "        x1 = tf.keras.layers.Conv2D(filters, 1, strides=1, padding=\"same\", kernel_initializer=initializer)(skip_resized)\n",
    "        attn = tf.keras.layers.Add()([g1, x1])\n",
    "        attn = tf.keras.layers.Activation(\"relu\")(attn)\n",
    "        attn = tf.keras.layers.Conv2D(1, 1, strides=1, padding=\"same\", kernel_initializer=initializer)(attn)\n",
    "        attn = tf.keras.layers.Activation(\"sigmoid\")(attn)\n",
    "\n",
    "        # Apply Attention\n",
    "        skip_attention = tf.keras.layers.Multiply()([skip_resized, attn])\n",
    "\n",
    "        # Transposed Convolution for upsampling\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding=\"same\", kernel_initializer=initializer)(x)\n",
    "        if use_dropout:\n",
    "            x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "        # Resize skip_attention to ensure shape compatibility with x\n",
    "        skip_attention_resized = tf.keras.layers.Resizing(x.shape[1], x.shape[2])(skip_attention)\n",
    "\n",
    "        # Combine the upsampled tensor with the attended skip connection\n",
    "        return tf.keras.layers.Concatenate()([x, skip_attention_resized])\n",
    "\n",
    "\n",
    "\n",
    "    # Downsampling Path\n",
    "    x = inputs\n",
    "    skips = []\n",
    "    down_filters = [64, 128, 256, 512, 512, 512, 512, 512]\n",
    "\n",
    "    for i, filters in enumerate(down_filters):\n",
    "        x = residual_downsample(x, filters, size=4, use_instance_norm=(i > 0))\n",
    "        skips.append(x)\n",
    "\n",
    "    # Bottleneck\n",
    "    x = tf.keras.layers.Conv2D(512, 4, strides=2, padding=\"same\", kernel_initializer=initializer)(x)\n",
    "    x = tfa.layers.InstanceNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Reverse the skip connections for upsampling\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling Path\n",
    "    up_filters = [512, 512, 512, 512, 256, 128, 64]\n",
    "\n",
    "    for i, (filters, skip) in enumerate(zip(up_filters, skips)):\n",
    "        x = attention_upsample(x, skip, filters, size=4, use_dropout=(i < 3))\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = tf.keras.layers.Conv2DTranspose(\n",
    "        filters=output_channels,\n",
    "        kernel_size=4,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=initializer,\n",
    "        activation=\"tanh\"\n",
    "    )(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T08:27:16.532441Z",
     "iopub.status.busy": "2020-08-29T08:27:16.531535Z",
     "iopub.status.idle": "2020-08-29T08:27:16.534854Z",
     "shell.execute_reply": "2020-08-29T08:27:16.534266Z"
    },
    "papermill": {
     "duration": 0.030335,
     "end_time": "2020-08-29T08:27:16.534977",
     "exception": false,
     "start_time": "2020-08-29T08:27:16.504642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape=(256, 256, 3)):\n",
    "\n",
    "    initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "    # Input layer\n",
    "    inp = tf.keras.layers.Input(shape=input_shape, name=\"input_image\")\n",
    "\n",
    "    # Residual Downsampling Block\n",
    "    def residual_downsample(x, filters, size, strides=2, use_instance_norm=True):\n",
    "        conv = tf.keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=size,\n",
    "            strides=strides,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=initializer,\n",
    "            use_bias=False\n",
    "        )(x)\n",
    "        if use_instance_norm:\n",
    "            conv = tfa.layers.InstanceNormalization()(conv)\n",
    "        conv = tf.keras.layers.LeakyReLU()(conv)\n",
    "\n",
    "        # Residual connection\n",
    "        shortcut = tf.keras.layers.Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=strides,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=initializer,\n",
    "            use_bias=False\n",
    "        )(x)\n",
    "        return tf.keras.layers.Add()([conv, shortcut])\n",
    "\n",
    "    # Downsampling Path\n",
    "    x = inp\n",
    "    down1 = residual_downsample(x, 64, 4, strides=2, use_instance_norm=False)  # (bs, 128, 128, 64)\n",
    "    down2 = residual_downsample(down1, 128, 4, strides=2)  # (bs, 64, 64, 128)\n",
    "    down3 = residual_downsample(down2, 256, 4, strides=2)  # (bs, 32, 32, 256)\n",
    "    down4 = residual_downsample(down3, 512, 4, strides=1)  # (bs, 32, 32, 512)\n",
    "\n",
    "    # Zero padding for boundary handling\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down4)  # (bs, 34, 34, 512)\n",
    "\n",
    "    # Convolutional Layer\n",
    "    conv1 = tf.keras.layers.Conv2D(\n",
    "        filters=512,\n",
    "        kernel_size=4,\n",
    "        strides=1,\n",
    "        padding=\"valid\",\n",
    "        kernel_initializer=initializer,\n",
    "        use_bias=False\n",
    "    )(zero_pad1)\n",
    "    conv1 = tfa.layers.InstanceNormalization()(conv1)\n",
    "    conv1 = tf.keras.layers.LeakyReLU()(conv1)\n",
    "\n",
    "    # Second Zero Padding\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(conv1)  # (bs, 36, 36, 512)\n",
    "\n",
    "    # Final Output Layer\n",
    "    outputs = tf.keras.layers.Conv2D(\n",
    "        filters=1,\n",
    "        kernel_size=4,\n",
    "        strides=1,\n",
    "        padding=\"valid\",\n",
    "        kernel_initializer=initializer\n",
    "    )(zero_pad2)  # (bs, 33, 33, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=inp, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T08:27:16.568360Z",
     "iopub.status.busy": "2020-08-29T08:27:16.567608Z",
     "iopub.status.idle": "2020-08-29T08:27:26.527227Z",
     "shell.execute_reply": "2020-08-29T08:27:26.526444Z"
    },
    "papermill": {
     "duration": 9.978841,
     "end_time": "2020-08-29T08:27:26.527361",
     "exception": false,
     "start_time": "2020-08-29T08:27:16.548520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    monet_generator = build_generator() # transforms photos to Monet-esque paintings\n",
    "    photo_generator = build_generator() # transforms Monet paintings to be more like photos\n",
    "\n",
    "    monet_discriminator = build_discriminator() # differentiates real Monet paintings and generated Monet paintings\n",
    "    photo_discriminator = build_discriminator() # differentiates real photos and generated photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T08:27:27.381412Z",
     "iopub.status.busy": "2020-08-29T08:27:27.380367Z",
     "iopub.status.idle": "2020-08-29T08:27:27.382858Z",
     "shell.execute_reply": "2020-08-29T08:27:27.383391Z"
    },
    "papermill": {
     "duration": 0.049519,
     "end_time": "2020-08-29T08:27:27.383553",
     "exception": false,
     "start_time": "2020-08-29T08:27:27.334034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CycleGan(keras.Model):\n",
    "    def __init__(self, monet_generator, photo_generator, monet_discriminator, photo_discriminator, lambda_cycle=10):\n",
    "\n",
    "        super().__init__()\n",
    "        self.monet_gen = monet_generator\n",
    "        self.photo_gen = photo_generator\n",
    "        self.monet_disc = monet_discriminator\n",
    "        self.photo_disc = photo_discriminator\n",
    "        self.lambda_cycle = lambda_cycle\n",
    "\n",
    "    def compile(self, \n",
    "                monet_gen_optimizer, \n",
    "                photo_gen_optimizer, \n",
    "                monet_disc_optimizer, \n",
    "                photo_disc_optimizer, \n",
    "                gen_loss_fn, \n",
    "                disc_loss_fn, \n",
    "                cycle_loss_fn, \n",
    "                identity_loss_fn):\n",
    "\n",
    "        super(CycleGan, self).compile()\n",
    "        self.monet_gen_optimizer = monet_gen_optimizer\n",
    "        self.photo_gen_optimizer = photo_gen_optimizer\n",
    "        self.monet_disc_optimizer = monet_disc_optimizer\n",
    "        self.photo_disc_optimizer = photo_disc_optimizer\n",
    "        self.gen_loss_fn = gen_loss_fn\n",
    "        self.disc_loss_fn = disc_loss_fn\n",
    "        self.cycle_loss_fn = cycle_loss_fn\n",
    "        self.identity_loss_fn = identity_loss_fn\n",
    "\n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "\n",
    "        real_monet, real_photo = batch_data\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Forward cycle: Photo -> Monet -> Photo\n",
    "            fake_monet = self.monet_gen(real_photo, training=True)\n",
    "            cycled_photo = self.photo_gen(fake_monet, training=True)\n",
    "\n",
    "            # Backward cycle: Monet -> Photo -> Monet\n",
    "            fake_photo = self.photo_gen(real_monet, training=True)\n",
    "            cycled_monet = self.monet_gen(fake_photo, training=True)\n",
    "\n",
    "            # Identity mappings\n",
    "            same_monet = self.monet_gen(real_monet, training=True)\n",
    "            same_photo = self.photo_gen(real_photo, training=True)\n",
    "\n",
    "            # Discriminator outputs\n",
    "            disc_real_monet = self.monet_disc(real_monet, training=True)\n",
    "            disc_real_photo = self.photo_disc(real_photo, training=True)\n",
    "            disc_fake_monet = self.monet_disc(fake_monet, training=True)\n",
    "            disc_fake_photo = self.photo_disc(fake_photo, training=True)\n",
    "\n",
    "            # Losses\n",
    "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
    "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
    "\n",
    "            cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n",
    "\n",
    "            monet_identity_loss = self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n",
    "            photo_identity_loss = self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n",
    "\n",
    "            total_monet_gen_loss = monet_gen_loss + cycle_loss + monet_identity_loss\n",
    "            total_photo_gen_loss = photo_gen_loss + cycle_loss + photo_identity_loss\n",
    "\n",
    "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
    "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
    "\n",
    "        # Compute gradients\n",
    "        monet_gen_grads = tape.gradient(total_monet_gen_loss, self.monet_gen.trainable_variables)\n",
    "        photo_gen_grads = tape.gradient(total_photo_gen_loss, self.photo_gen.trainable_variables)\n",
    "        monet_disc_grads = tape.gradient(monet_disc_loss, self.monet_disc.trainable_variables)\n",
    "        photo_disc_grads = tape.gradient(photo_disc_loss, self.photo_disc.trainable_variables)\n",
    "\n",
    "        # Apply gradients\n",
    "        self.monet_gen_optimizer.apply_gradients(zip(monet_gen_grads, self.monet_gen.trainable_variables))\n",
    "        self.photo_gen_optimizer.apply_gradients(zip(photo_gen_grads, self.photo_gen.trainable_variables))\n",
    "        self.monet_disc_optimizer.apply_gradients(zip(monet_disc_grads, self.monet_disc.trainable_variables))\n",
    "        self.photo_disc_optimizer.apply_gradients(zip(photo_disc_grads, self.photo_disc.trainable_variables))\n",
    "\n",
    "        # Return loss metrics\n",
    "        return {\n",
    "            \"monet_gen_loss\": total_monet_gen_loss,\n",
    "            \"photo_gen_loss\": total_photo_gen_loss,\n",
    "            \"monet_disc_loss\": monet_disc_loss,\n",
    "            \"photo_disc_loss\": photo_disc_loss,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T08:27:27.450634Z",
     "iopub.status.busy": "2020-08-29T08:27:27.449541Z",
     "iopub.status.idle": "2020-08-29T08:27:27.452601Z",
     "shell.execute_reply": "2020-08-29T08:27:27.453213Z"
    },
    "papermill": {
     "duration": 0.02693,
     "end_time": "2020-08-29T08:27:27.453371",
     "exception": false,
     "start_time": "2020-08-29T08:27:27.426441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def discriminator_loss(real_output, fake_output):\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "        real_loss = bce(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = bce(tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return 0.5 * total_loss\n",
    "\n",
    "    def generator_loss(fake_output):\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "        return bce(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "    def cycle_consistency_loss(real_image, cycled_image, lambda_cycle):\n",
    "        loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "        return lambda_cycle * loss\n",
    "\n",
    "    def identity_loss(real_image, same_image, lambda_identity):\n",
    "        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "        return lambda_identity * 0.5 * loss\n",
    "\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "with strategy.scope():\n",
    "    cycle_gan_model = CycleGan(\n",
    "        monet_generator, photo_generator, monet_discriminator, photo_discriminator\n",
    "    )\n",
    "\n",
    "    cycle_gan_model.compile(\n",
    "        monet_gen_optimizer=monet_generator_optimizer,\n",
    "        photo_gen_optimizer=photo_generator_optimizer,\n",
    "        monet_disc_optimizer=monet_discriminator_optimizer,\n",
    "        photo_disc_optimizer=photo_discriminator_optimizer,\n",
    "        gen_loss_fn=generator_loss,\n",
    "        disc_loss_fn=discriminator_loss,\n",
    "        cycle_loss_fn=cycle_consistency_loss,\n",
    "        identity_loss_fn=identity_loss\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T08:27:27.842380Z",
     "iopub.status.busy": "2020-08-29T08:27:27.836985Z",
     "iopub.status.idle": "2020-08-29T08:45:16.338257Z",
     "shell.execute_reply": "2020-08-29T08:45:16.337486Z"
    },
    "papermill": {
     "duration": 1068.52287,
     "end_time": "2020-08-29T08:45:16.338383",
     "exception": false,
     "start_time": "2020-08-29T08:27:27.815513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 13:14:19.858730: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-11-30 13:14:19.859030: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [5]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-11-30 13:14:40.336348: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-11-30 13:14:43.623572: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 370s 991ms/step - monet_gen_loss: 7.0882 - photo_gen_loss: 7.2841 - monet_disc_loss: 0.6593 - photo_disc_loss: 0.6366\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 304s 1s/step - monet_gen_loss: 4.9186 - photo_gen_loss: 5.1076 - monet_disc_loss: 0.6469 - photo_disc_loss: 0.6117\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 301s 1s/step - monet_gen_loss: 4.6939 - photo_gen_loss: 4.9014 - monet_disc_loss: 0.6223 - photo_disc_loss: 0.5765\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 286s 953ms/step - monet_gen_loss: 4.7044 - photo_gen_loss: 4.8627 - monet_disc_loss: 0.5851 - photo_disc_loss: 0.5613\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 299s 999ms/step - monet_gen_loss: 5.5436 - photo_gen_loss: 5.2049 - monet_disc_loss: 0.4399 - photo_disc_loss: 0.5331\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 286s 954ms/step - monet_gen_loss: 5.6867 - photo_gen_loss: 5.2575 - monet_disc_loss: 0.4459 - photo_disc_loss: 0.5379\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 278s 927ms/step - monet_gen_loss: 5.6719 - photo_gen_loss: 5.2225 - monet_disc_loss: 0.4302 - photo_disc_loss: 0.5227\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 306s 1s/step - monet_gen_loss: 5.4037 - photo_gen_loss: 5.1860 - monet_disc_loss: 0.4578 - photo_disc_loss: 0.5009\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 295s 983ms/step - monet_gen_loss: 5.5790 - photo_gen_loss: 5.3102 - monet_disc_loss: 0.4315 - photo_disc_loss: 0.4950\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 297s 990ms/step - monet_gen_loss: 5.4967 - photo_gen_loss: 5.3169 - monet_disc_loss: 0.4454 - photo_disc_loss: 0.5009\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 300s 1s/step - monet_gen_loss: 5.4998 - photo_gen_loss: 5.4023 - monet_disc_loss: 0.4464 - photo_disc_loss: 0.4894\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 295s 983ms/step - monet_gen_loss: 5.5051 - photo_gen_loss: 5.5001 - monet_disc_loss: 0.4566 - photo_disc_loss: 0.4735\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 280s 934ms/step - monet_gen_loss: 5.5194 - photo_gen_loss: 5.6507 - monet_disc_loss: 0.4619 - photo_disc_loss: 0.4733\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 284s 948ms/step - monet_gen_loss: 5.5698 - photo_gen_loss: 5.5239 - monet_disc_loss: 0.4454 - photo_disc_loss: 0.4842\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 291s 972ms/step - monet_gen_loss: 5.6462 - photo_gen_loss: 5.5912 - monet_disc_loss: 0.4324 - photo_disc_loss: 0.4869\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 291s 970ms/step - monet_gen_loss: 5.5357 - photo_gen_loss: 5.4688 - monet_disc_loss: 0.4515 - photo_disc_loss: 0.5021\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 287s 957ms/step - monet_gen_loss: 5.4995 - photo_gen_loss: 5.4870 - monet_disc_loss: 0.4568 - photo_disc_loss: 0.4860\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 278s 926ms/step - monet_gen_loss: 5.4794 - photo_gen_loss: 5.5245 - monet_disc_loss: 0.4517 - photo_disc_loss: 0.4749\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 302s 1s/step - monet_gen_loss: 5.5347 - photo_gen_loss: 5.5293 - monet_disc_loss: 0.4351 - photo_disc_loss: 0.4840\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 290s 964ms/step - monet_gen_loss: 5.5756 - photo_gen_loss: 5.5773 - monet_disc_loss: 0.4413 - photo_disc_loss: 0.4721\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 272s 908ms/step - monet_gen_loss: 5.5516 - photo_gen_loss: 5.5988 - monet_disc_loss: 0.4398 - photo_disc_loss: 0.4699\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 303s 1s/step - monet_gen_loss: 5.4868 - photo_gen_loss: 5.5674 - monet_disc_loss: 0.4543 - photo_disc_loss: 0.4739\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 294s 978ms/step - monet_gen_loss: 5.4230 - photo_gen_loss: 5.5645 - monet_disc_loss: 0.4565 - photo_disc_loss: 0.4652\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 299s 997ms/step - monet_gen_loss: 5.4924 - photo_gen_loss: 5.6419 - monet_disc_loss: 0.4524 - photo_disc_loss: 0.4635\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 291s 970ms/step - monet_gen_loss: 5.5345 - photo_gen_loss: 5.6903 - monet_disc_loss: 0.4267 - photo_disc_loss: 0.4631\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 308s 1s/step - monet_gen_loss: 5.4321 - photo_gen_loss: 5.6201 - monet_disc_loss: 0.4667 - photo_disc_loss: 0.4608\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 308s 1s/step - monet_gen_loss: 5.3546 - photo_gen_loss: 5.6223 - monet_disc_loss: 0.4636 - photo_disc_loss: 0.4612\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 303s 1s/step - monet_gen_loss: 5.4270 - photo_gen_loss: 5.6572 - monet_disc_loss: 0.4496 - photo_disc_loss: 0.4512\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 317s 1s/step - monet_gen_loss: 5.4302 - photo_gen_loss: 5.7133 - monet_disc_loss: 0.4594 - photo_disc_loss: 0.4541\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 324s 1s/step - monet_gen_loss: 5.4125 - photo_gen_loss: 5.6685 - monet_disc_loss: 0.4473 - photo_disc_loss: 0.4578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2491a2190>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "cycle_gan_model.fit(\n",
    "    tf.data.Dataset.zip((dataset_monet, dataset_photo)),\n",
    "    epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T08:45:24.898093Z",
     "iopub.status.busy": "2020-08-29T08:45:24.897216Z",
     "iopub.status.idle": "2020-08-29T09:21:45.221956Z",
     "shell.execute_reply": "2020-08-29T09:21:45.221049Z"
    },
    "papermill": {
     "duration": 2180.855246,
     "end_time": "2020-08-29T09:21:45.222099",
     "exception": false,
     "start_time": "2020-08-29T08:45:24.366853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "i = 1\n",
    "for img in dataset_photo:\n",
    "    prediction = monet_generator(img, training=False)[0].numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    im = PIL.Image.fromarray(prediction)\n",
    "    im.save(\"/Users/kylewong/Downloads/NN_Project_Week_5/images/\" + str(i) + \".jpg\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:21:46.345701Z",
     "iopub.status.busy": "2020-08-29T09:21:46.344786Z",
     "iopub.status.idle": "2020-08-29T09:21:50.874034Z",
     "shell.execute_reply": "2020-08-29T09:21:50.874615Z"
    },
    "papermill": {
     "duration": 5.118423,
     "end_time": "2020-08-29T09:21:50.874795",
     "exception": false,
     "start_time": "2020-08-29T09:21:45.756372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kylewong/Downloads/NN_Project_Week_5/images.zip'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"/Users/kylewong/Downloads/NN_Project_Week_5/images/\", 'zip', \"/Users/kylewong/Downloads/NN_Project_Week_5/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "monet_generator.save(\"/Users/kylewong/Downloads/NN_Project_Week_5/monet_generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "2024-11-30 20:04:09.870854: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-30 20:04:09.870895: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#import InstantceNormalization\n",
    "import tensorflow_addons as tfa\n",
    "monet_generator = keras.models.load_model(\"/Users/kylewong/Downloads/NN_Project_Week_5/monet_generator_copy.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "duration": 3295.767085,
   "end_time": "2020-08-29T09:21:52.609073",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-29T08:26:56.841988",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
